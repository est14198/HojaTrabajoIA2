{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOJA DE TRABAJO 2\n",
    "## MARIA FERNANDA 14198\n",
    "\n",
    "Primero importamos las funciones del archivo metodos_redes.py que contienen los algoritmos de back propagation, feed forward, costo, calculo del jacobiano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metodos_redes import funcion_costo, formar_matrices, jacobiano, feed_forward\n",
    "from mnist_reader import load_mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de datos\n",
    "\n",
    "Se utilizará para este analisis el set de datos fashion-mnist que contiene una variedad de imagenes a blanco y negro representando 10 diferentes categorías de ropa. Como set de entrenamiento se utilizara el conjunto de imagenes train que consiste de 60000 imagenes y para las pruebas se utilizara el conjunto test que contiene 10000 imagenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer datos de csv\n",
    "train_data = np.genfromtxt('fashion-mnist_train.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "X_entrenamiento = np.delete(train_data, 0, 1)\n",
    "y_entrenamiento = [row[0] for row in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.genfromtxt('fashion-mnist_test.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "X_prueba = np.delete(test_data, 0, 1)\n",
    "y_prueba = [row[0] for row in test_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenando el modelo\n",
    "\n",
    "Para entrenar el modelo se definarán primero las capas. Nuestro modelo tendrá 3 capas diferentes. La capa de entrada está compuesta de una neurona por pixel de las imagenes. La capa oculta esta compuesta por 100 neuronas. La capa de salida esta compuesta de 10 neuronas cada una correspondiente a uno de los tipos de ropa.\n",
    "\n",
    "Antes de realizar el entrenamiento normalizamos los datos de las imagenes para llevarlos de un rango de 0 a 1. Las clases en Y deben de ser transformadas de un rango de un entero a su representacion en un arreglo de diez posiciones, donde la primera clase se ve de la forma [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import math\n",
    "import scipy\n",
    "from scipy.optimize import minimize\n",
    "from functools import reduce\n",
    "\n",
    "sigmoid = lambda x: 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "flatten_list_of_arrays = lambda list_of_arrays: reduce(\n",
    "    lambda acc, v: np.array([*acc.flatten(), *v.flatten()]),\n",
    "    list_of_arrays\n",
    ")\n",
    "\n",
    "X_normalizado = X_entrenamiento / 1000.0\n",
    "m, n = X_normalizado.shape\n",
    "\n",
    "Y_modificado = y_entrenamiento.reshape(m, 1)\n",
    "Y_modificado = (Y_modificado == np.array(range(10))).astype(int)\n",
    "\n",
    "layers = np.array([\n",
    "    n, # Se utilizaran el numero de pixeles como capa de entrada\n",
    "    100, # Se utilizaran 100 neuronas en la capa oculta\n",
    "    10 # Estas son las clases a identificar\n",
    "])\n",
    "\n",
    "theta_shapes = np.hstack((\n",
    "    layers[1:].reshape(len(layers) - 1, 1),\n",
    "    (layers[:-1] + 1).reshape(len(layers) - 1, 1)\n",
    "))\n",
    "\n",
    "flat_thetas = flatten_list_of_arrays([\n",
    "    np.random.rand(*theta_shape)\n",
    "    for theta_shape in theta_shapes\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos el proceso de entrenamiento. Este proceso tardo al rededor de 1 hora en completarse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ENTRENANDO!\")\n",
    "\n",
    "result = minimize(\n",
    "    fun = funcion_costo,\n",
    "    x0 = flat_thetas,\n",
    "    args = (theta_shapes, X_normalizado, Y_modificado),\n",
    "    method = 'L-BFGS-B',\n",
    "    jac = jacobiano,\n",
    "    options = {'disp': True, 'maxiter': 1000} # Se establecen 1000 iteraciones como max\n",
    ")\n",
    "\n",
    "outfile = open('modelo', 'wb')\n",
    "pickle.dump(result.x, outfile)\n",
    "outfile.close()\n",
    "\n",
    "print(\"FINALIZADO!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de prueba\n",
    "\n",
    "Para probar nuestro modelo haremos el mismo procesamiento de datos que al entrenarlo. Luego definimos la misma estructura de la red neuronal y procedemos a realizar las predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "import pickle\n",
    "from functools import reduce\n",
    "\n",
    "flatten_list_of_arrays = lambda list_of_arrays: reduce(\n",
    "    lambda acc, v: np.array([*acc.flatten(), *v.flatten()]),\n",
    "    list_of_arrays\n",
    ")\n",
    "\n",
    "X_normalizado = X_prueba / 1000.0\n",
    "m, n = X_normalizado.shape\n",
    "\n",
    "layers = np.array([\n",
    "    n,\n",
    "    100,\n",
    "    10\n",
    "])\n",
    "\n",
    "theta_shapes = np.hstack((\n",
    "    layers[1:].reshape(len(layers) - 1, 1),\n",
    "    (layers[:-1] + 1).reshape(len(layers) - 1, 1)\n",
    "))\n",
    "\n",
    "openfile = open(\"modelo\", \"rb\")\n",
    "thetas_trained = pickle.load(openfile)\n",
    "\n",
    "thetas = formar_matrices(thetas_trained, theta_shapes)\n",
    "\n",
    "predicciones = feed_forward(thetas, X_normalizado)[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados\n",
    "\n",
    "\n",
    "Se comparan las predicciones con las clases reales proveidas por el set de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches: 8604\n",
      "Precision: 86.04%\n"
     ]
    }
   ],
   "source": [
    "matches = 0\n",
    "\n",
    "for i in range(m):\n",
    "    clase = np.where((predicciones[i] == np.amax(predicciones[i])))[0]\n",
    "\n",
    "    if(clase == y_prueba[i]):\n",
    "        matches += 1\n",
    "    \n",
    "\n",
    "precision = (matches/m)*100\n",
    "\n",
    "print('Matches: ' + str(matches))\n",
    "print('Precision: ' + str(precision) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que la precisión del algoritmo fue bastante buena con un 86.04%. Se probaron +-10 capas ocultas y esta configuracion dió el mejor resultado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
